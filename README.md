# Human-Robot Musical Synchronization: PhD Thesis Presentation

[![Maynooth University](https://img.shields.io/badge/Institution-Maynooth%20University-green.svg)](https://www.maynoothuniversity.ie/)
[![Research Area](https://img.shields.io/badge/Research-Robotic%20Musicianship-blue.svg)](#)
[![License](https://img.shields.io/badge/License-Academic-orange.svg)](#)
[![Live Demo](https://img.shields.io/badge/Demo-Live%20Presentation-red.svg)](https://sutirthachakraborty.github.io/PhD-Sutirtha-Presentation/)

> **Multimodal Approaches for Real-Time Musical Collaboration**  
> *PhD Thesis by Sutirtha Chakraborty*  
> *Maynooth University - National University of Ireland Maynooth*

## ğŸŒ Live Presentation

**ğŸ¯ [View Live Presentation â†’](https://sutirthachakraborty.github.io/PhD-Sutirtha-Presentation/)**

Experience the full interactive thesis presentation with rich multimedia content, mathematical equations, and seamless chapter navigation.

## ğŸ¼ Abstract

This repository contains the interactive web presentation of my PhD thesis exploring the cutting-edge field of **Robotic Musicianship**. The research focuses on developing machine intelligence through algorithms and cognitive models to capture musical perception, composition, and performance capabilities, enabling robots to participate in cooperative musical ensembles with humans.

The core innovation lies in addressing the challenge of **real-time synchronization** in human-robot musical collaborations, where human performers naturally express with the 'feel' of music and leadership roles change fluidly within the ensemble.

### ğŸ”¬ Research Innovation

**Dual Strategy Approach:**
- **ğŸµ Mapping Phase:** Control and sensing of musical instrument components with sound synthesis parameters
- **ğŸ¤– Modeling Phase:** Deep learning models to capture overall musical process representation

**Mathematical Foundation:**
Each musician (human or robot) is modeled as a separate oscillator using the **Kuramoto synchronization algorithm**, combined with **LSTM neural networks** for predictive musical modeling.

## ğŸ—ï¸ Repository Structure

```
ğŸ“ PhD-Sutirtha-Presentation/
â”œâ”€â”€ ğŸ“„ index.html              # Main presentation landing page
â”œâ”€â”€ ğŸ“„ chapter[1-8].html       # Individual chapter presentations
â”œâ”€â”€ ğŸ“„ [chap1-8].txt          # LaTeX source content for chapters
â”œâ”€â”€ ğŸ“„ abstract.txt            # Thesis abstract
â”œâ”€â”€ ğŸ“„ intro.txt               # Introduction content
â”œâ”€â”€ ğŸ“„ styles.css              # Custom styling for presentation
â”œâ”€â”€ ğŸ“„ main.js                 # Interactive JavaScript functionality
â”œâ”€â”€ ğŸ“„ list_of_public.txt      # Publications list
â””â”€â”€ ğŸ“ images/                 # Research figures and diagrams
    â”œâ”€â”€ ğŸ“ introduction/       # Intro chapter visuals
    â”œâ”€â”€ ğŸ“ literature/         # Literature review figures
    â”œâ”€â”€ ğŸ“ leaderStem/         # LeaderSTeM algorithm visuals
    â”œâ”€â”€ ğŸ“ Multimodal/         # Multimodal framework diagrams
    â”œâ”€â”€ ğŸ“ nature/             # Nature of music sync figures
    â”œâ”€â”€ ğŸ“ virtual/            # Virtual implementation visuals
    â”œâ”€â”€ ğŸ“ visual/             # Visual cue processing images
    â””â”€â”€ ğŸ“ dynamic/            # Dynamic content figures
```

## ğŸ¯ Key Research Contributions

### 1. ğŸ¼ Cyborg Philharmonic Framework
Novel multimodal synchronization system integrating audio, visual, and gestural cues for seamless human-robot musical collaboration.

### 2. ğŸ¯ LeaderSTeM Algorithm
Advanced LSTM-based machine learning approach for dynamic leader identification and tracking in musical ensembles.

### 3. ğŸ‘ï¸ Visual Synchronization
Integration of computer vision techniques for gesture-based musical synchronization and conductor following.

### 4. ğŸ”„ Real-time Adaptation
Continuous learning mechanisms that adapt to individual performance styles and changing musical contexts.

## ğŸ“š Thesis Structure

| Chapter | Title | Focus Area |
|---------|-------|------------|
| **Ch 1** | [Introduction](chapter1.html) | Historical context and research challenges |
| **Ch 2** | [Literature Review](chapter2.html) | Existing work and research gaps |
| **Ch 3** | [Cyborg Philharmonic Framework](chapter3.html) | Multimodal synchronization architecture |
| **Ch 4** | [LeaderSTeM](chapter4.html) | Audio-based ensemble leadership tracking |
| **Ch 5** | [Visual Cues](chapter5.html) | Visual signals in musical synchronization |
| **Ch 6** | [Multimodal Synchronization](chapter6.html) | Integration of multiple modalities |
| **Ch 7** | [Implementation](chapter7.html) | Real-world system validation |
| **Ch 8** | [Conclusion](chapter8.html) | Contributions and future work |

## ğŸš€ Getting Started

### Prerequisites
- Modern web browser (Chrome, Firefox, Safari, Edge)
- No additional dependencies required

### Running the Presentation
1. Clone this repository:
   ```bash
   git clone https://github.com/[username]/PhD-Sutirtha-Presentation.git
   cd PhD-Sutirtha-Presentation
   ```

2. Open the presentation:
   ```bash
   # Method 1: Open directly in browser
   open index.html
   
   # Method 2: Serve locally (recommended)
   python -m http.server 8000
   # Then visit: http://localhost:8000
   ```

3. Navigate through chapters using the interactive menu

## ğŸ”¬ Technical Approach

### Mathematical Foundation
```
Î¸Ì‡áµ¢ = Ï‰áµ¢ + (K/N) Î£â±¼ sin(Î¸â±¼ - Î¸áµ¢)
```
*Kuramoto Model for Oscillator Synchronization*

### Key Technologies
- **Machine Learning:** LSTM Neural Networks, Random Forest, SVM
- **Computer Vision:** OpenPose, Motion Analysis, Gesture Recognition  
- **Signal Processing:** Audio onset detection, Beat tracking, Spectral analysis
- **Synchronization:** Kuramoto oscillators, Phase-locked loops
- **Real-time Systems:** Low-latency audio processing, Predictive modeling

## ğŸ“Š Research Impact

### Publications (13 papers, 125+ citations)
- **Most Cited:** "The Cyborg Philharmonic: Synchronizing interactive musical performances between humans and machines" (25 citations)
- **Recent Work:** Multimodal synchronization, Gesture-based interfaces, IoMT applications
- **Core Algorithms:** LeaderSTeM, Visual beat estimation, Touchless interaction

### Key Metrics
- ğŸ¯ **125+ Total Citations**
- ğŸ“š **13 Peer-reviewed Publications**
- ğŸ•’ **6 Years Active Research**
- ğŸ† **Multiple Conference Presentations**

## ğŸ¨ Features

### Interactive Presentation
- **ğŸ“± Responsive Design:** Works on desktop, tablet, and mobile
- **ğŸ¯ Progress Tracking:** Visual progress bar and navigation
- **ğŸ” Rich Content:** Mathematical equations, interactive diagrams
- **ğŸ’¡ Tooltips:** Contextual explanations for technical terms
- **ğŸ¨ Professional Styling:** Academic presentation aesthetics

### Technical Highlights
- Pure HTML/CSS/JS implementation
- No external dependencies
- Fast loading and smooth navigation
- Academic-quality typography and layout

## ğŸ”§ Customization

### Styling
The presentation uses custom CSS with:
- Academic color scheme
- Responsive grid layouts
- Smooth animations and transitions
- Print-friendly formatting

### Content Updates
- Chapter content stored in separate `.txt` files
- Images organized by chapter/topic
- Modular structure for easy updates

## ğŸ¤ Contributing

This is an academic presentation repository. For questions about the research:

- **Email:** [your-email@university.edu]
- **LinkedIn:** [Your LinkedIn Profile]
- **ResearchGate:** [Your ResearchGate Profile]
- **Google Scholar:** [Your Scholar Profile]

## ğŸ“„ License

This work is licensed under Academic License. The research content, methodologies, and findings are proprietary to the thesis work. Please cite appropriately if referencing this work.

## ğŸ“ Citation

If you reference this work, please cite:

```bibtex
@phdthesis{chakraborty2024human,
  title={Human-Robot Musical Synchronization: Multimodal Approaches for Real-Time Musical Collaboration},
  author={Chakraborty, Sutirtha},
  year={2024},
  school={Maynooth University},
  address={National University of Ireland Maynooth}
}
```

## ğŸŒŸ Acknowledgments

- **Supervisor:** Prof. Joseph Timoney, Maynooth University
- **Institution:** Maynooth University - National University of Ireland Maynooth
- **Research Group:** [Music Technology Research Group]
- **Funding:** [Grant/Funding Information]

---

**ğŸµ "Driving closer towards a vision of a human-robot symphonic orchestra" ğŸ¤–**

*For the full thesis document and additional resources, please contact the author.*